{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 多维数组的运算\n",
    "### 多维数组\n",
    "获取维数通过np.ndim()函数获得\n",
    "数组的形状通过np.shape()函数获得\n",
    "二维数组也称为矩阵(matrix)。\n",
    "数组的横向排列称为行(row)，纵向排列称为列(column)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "1\n",
      "2\n",
      "(4,)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([1, 2, 3, 4])\n",
    "B = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "print(A)\n",
    "print(B)\n",
    "print(np.ndim(A))  #获取维数\n",
    "print(np.ndim(B))  #获取维数\n",
    "print(np.shape(A))  #获取形状\n",
    "print(np.shape(B))  #获取形状\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 矩阵乘法\n",
    " $2×3$的矩阵和$3 × 2$的矩阵的乘积实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3, 2)\n",
      "[[22 28]\n",
      " [49 64]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3]\n",
    "                 , [4, 5, 6]])\n",
    "print(A.shape)\n",
    "B = np.array([[1, 2]\n",
    "                 , [3, 4]\n",
    "                 , [5, 6]])\n",
    "print(B.shape)\n",
    "C = np.dot(A, B)\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "矩阵的乘积运算中，对应维度的元素个数要保持一致\n",
    "\n",
    "### 神经网络的内积\n",
    "使用NumPy矩阵来实现神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2])\n",
    "W = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "Y = np.dot(X, W)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "神经网络的晕眩可以作为矩阵运算打包进行。因为神经网络各层的运算是通过矩阵乘法运算打包进行的。\n",
    "权重和隐藏层的神经元的右上角有一个(1)，表示权重和神经元的层号\n",
    "右下角的两个数字，是后一层神经元和前一层神经元的索引号。\n",
    "$w_{{1}~{2}}^{(1)}$表示前一层的第2个神经元$x_2$到后一层的第一个神经元$a_1^{(1)}$的权重。\n",
    "权重右下角按照后一层的索引号，前一层的索引号的顺序排列\n",
    "\n",
    "\n",
    "### 各层之间信号传递的实现\n",
    "$a_{{1}}^{(1)}$=$w_{{1}~{1}}^{(1)}$$x_1$+$w_{{1}~{2}}^{(1)}$$x_2$+$b_{{1}}^{(1)}$\n",
    "如果使用矩阵乘法运算，则可以将第一层的加权和表示层下面的式子。\n",
    "$$\n",
    " A^{(1)}=XW^{(1)}+B^{(1)}\n",
    "$$\n",
    "$A_{(1)}$,$X$,$B_{(1)}$,$W_{(1)}$表示：\n",
    "$$\n",
    "A_{(1)}=\\bigl(\n",
    "    \\begin{matrix}\n",
    "\t\ta_{{1}}^{(1)}& a_{{2}}^{(1)}& a_{{3}}^{(1)}\n",
    "\t\\end{matrix}\n",
    "\\bigr)$ ~,~ X=$\\bigl(\n",
    "    \\begin{matrix}\n",
    "\t\tx_1&x_2\n",
    "\t\\end{matrix}\n",
    "\\bigr)\n",
    "$$\n",
    "\n",
    "$$\n",
    "B_{(1)}=\\bigl(\n",
    "    \\begin{matrix}\n",
    "\t\tb_1^{(1)}&b_2^{(1)}&b_3^{(1)}\n",
    "\t\\end{matrix}\n",
    "\\bigr)\n",
    "$$\n",
    "$$\n",
    "W_{(1)}=\n",
    "    \\begin{pmatrix}\n",
    "\t\tw_{{1}~{1}}^{(1)}&w_{{2}~{1}}^{(1)}&w_{{3}~{1}}^{(1)} \\\\\n",
    "        w_{{1}~{1}}^{(2)}&w_{{2}~{2}}^{(1)}&w_{{3}~{2}}^{(1)}\n",
    "\t\\end{pmatrix}\n",
    "\n",
    "$$\n",
    "以下使用NumPy多维数组来实现\n",
    "### 从输入层到第1层的信号传递"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "X = np.array([1.0, 0.5])  # 输入\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])  # 权重\n",
    "B1 = np.array([0.1, 0.2, 0.3])  #偏置\n",
    "A1 = np.dot(X, W1) + B1\n",
    "print(A1)\n",
    "Z1 = sigmoid(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### 实现第1层到第2层的信号传递\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])  #权重\n",
    "B2 = np.array([0.1, 0.2])  #偏置\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第二层到输出层的基本实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identity_function(A3)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里定义identity_function()函数，也称为\"恒等函数\"，并将其作为输出层的激活函数。恒等函数会将输入按照原样输出。\n",
    "输出层的激活函数用$\\sigma()$表示，不同于隐藏层的激活函数$h()$使用的为sigmoid()函数。\n",
    "\n",
    "- 输出层所用的激活函数根据求解问题的性质决定。一般回归问题使用恒等函数。二元分类问题使用sigmoid函数，多元分类问题使用softmax函数。\n",
    "\n",
    "---------\n",
    "\n",
    "### 三层神经网络的代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {  #定义字典\n",
    "        'W1': np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]), #权重\n",
    "        'b1': np.array([0.1, 0.2, 0.3]), # 偏置\n",
    "        'W2': np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]]),\n",
    "        'b2': np.array([0.1, 0.2]),\n",
    "        'W3': np.array([[0.1, 0.3], [0.2, 0.4]]),\n",
    "        'b3': np.array([0.1, 0.2])\n",
    "\n",
    "    }\n",
    "    return network\n",
    "\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    return y\n",
    "\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5]) # 输入信号\n",
    "y = forward(network, x)\n",
    "print(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}